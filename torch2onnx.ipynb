{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import json\n",
    "RATIO_DATA = 'data/ratio_data.json'\n",
    "ADVICE_MODEL = 'advice_resnet18_aug_1'\n",
    "ADVICE_ONE_MODEL = 'advice_one_resnet18_aug_1'\n",
    "ADVICE_TWO_MODEL = 'advice_two_resnet18_aug_2'\n",
    "ENCHANT_N_MODEL = 'enchant_n_resnet18_aug_1'\n",
    "OPTION_MODEL = 'option_resnet18_aug_1'\n",
    "\n",
    "with open(f'logs/{ADVICE_MODEL}/config.json') as f:\n",
    "    advice_config = json.load(f)\n",
    "advice_model = getattr(models, advice_config['model_name'])(**advice_config['model_kwargs'])\n",
    "advice_model.load_state_dict(torch.load(f'logs/{ADVICE_MODEL}/checkpoints/best_acc.pt'))\n",
    "advice_model = advice_model.eval()\n",
    "\n",
    "with open(f'logs/{ADVICE_ONE_MODEL}/config.json') as f:\n",
    "    advice_one_config = json.load(f)\n",
    "advice_one_model = getattr(models, advice_one_config['model_name'])(**advice_one_config['model_kwargs'])\n",
    "advice_one_model.load_state_dict(torch.load(f'logs/{ADVICE_ONE_MODEL}/checkpoints/best_acc.pt'))\n",
    "advice_one_model = advice_one_model.eval()\n",
    "\n",
    "with open(f'logs/{ADVICE_TWO_MODEL}/config.json') as f:\n",
    "    advice_two_config = json.load(f)\n",
    "advice_two_model = getattr(models, advice_two_config['model_name'])(**advice_two_config['model_kwargs'])\n",
    "advice_two_model.load_state_dict(torch.load(f'logs/{ADVICE_TWO_MODEL}/checkpoints/best_acc.pt'))\n",
    "advice_two_model = advice_two_model.eval()\n",
    "\n",
    "with open(f'logs/{ENCHANT_N_MODEL}/config.json') as f:\n",
    "    enchant_n_config = json.load(f)\n",
    "enchant_n_model = getattr(models, enchant_n_config['model_name'])(**enchant_n_config['model_kwargs'])\n",
    "enchant_n_model.load_state_dict(torch.load(f'logs/{ENCHANT_N_MODEL}/checkpoints/best_acc.pt'))\n",
    "enchant_n_model = enchant_n_model.eval()\n",
    "\n",
    "with open(f'logs/{OPTION_MODEL}/config.json') as f:\n",
    "    option_config = json.load(f)\n",
    "option_model = getattr(models, option_config['model_name'])(**option_config['model_kwargs'])\n",
    "option_model.load_state_dict(torch.load(f'logs/{OPTION_MODEL}/checkpoints/best_acc.pt'))\n",
    "option_model = option_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "advice_sample = torch.randn(1, 3, 64, 288)\n",
    "# enchants_sample = torch.randn(1, 3, 16, 32, requires_grad=True)\n",
    "# options_sample = torch.randn(1, 3, 20, 105, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    advice_output = advice_model(advice_sample)\n",
    "torch.onnx.export(\n",
    "    advice_model,\n",
    "    advice_sample,\n",
    "    'onnx_models/advice_resnet18_aug_1.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "ort_session = ort.InferenceSession('onnx_models/advice_resnet18_aug_1.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: np.random.random((10, 3, 64, 288)).astype(np.float32)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "# np.testing.assert_allclose(advice_output.detach().numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 132)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-319.90106 -305.30865 -275.81003 -297.64792 -221.13457 -210.89893\n",
      " -181.3021  -224.26352 -195.546   -245.26265]\n",
      "[-319.901   -305.3086  -275.80994 -297.64792 -221.13452 -210.8989\n",
      " -181.3021  -224.26355 -195.54602 -245.26263]\n"
     ]
    }
   ],
   "source": [
    "advice_one_sample = torch.randn(1, 3, 64, 288)\n",
    "with torch.no_grad():\n",
    "    advice_one_output = advice_one_model(advice_one_sample)\n",
    "torch.onnx.export(\n",
    "    advice_one_model,\n",
    "    advice_one_sample,\n",
    "    'onnx_models/advice_one_resnet18_aug_1.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "ort_session = ort.InferenceSession('onnx_models/advice_one_resnet18_aug_1.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: advice_one_sample.detach().numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "np.testing.assert_allclose(advice_one_output.detach().numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(advice_one_output.detach().numpy()[0][:10])\n",
    "print(ort_outs[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-49.20324  -48.14781  -47.634052 -55.616154 -66.9009   -39.733562\n",
      " -45.83955  -57.330097 -49.242924 -55.50102 ]\n",
      "[-49.203224 -48.147804 -47.63404  -55.616142 -66.900894 -39.73356\n",
      " -45.83953  -57.330093 -49.242916 -55.501007]\n"
     ]
    }
   ],
   "source": [
    "advice_two_sample = torch.randn(1, 3, 64, 288)\n",
    "with torch.no_grad():\n",
    "    advice_two_output = advice_two_model(advice_two_sample)\n",
    "torch.onnx.export(\n",
    "    advice_two_model,\n",
    "    advice_two_sample,\n",
    "    'onnx_models/advice_two_resnet18_aug_2.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "ort_session = ort.InferenceSession('onnx_models/advice_two_resnet18_aug_2.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: advice_two_sample.detach().numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "np.testing.assert_allclose(advice_two_output.detach().numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(advice_two_output.detach().numpy()[0][:10])\n",
    "print(ort_outs[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42014518 -2.271747   -2.8423336  -0.9598536   5.0915184   3.7943265\n",
      " -3.5288858  -0.6669427  -0.33164066 -3.078349  ]\n",
      "[-0.42014426 -2.2717438  -2.8423324  -0.95985496  5.0915127   3.7943254\n",
      " -3.5288806  -0.6669439  -0.3316393  -3.078349  ]\n"
     ]
    }
   ],
   "source": [
    "enchant_n_sample = torch.randn(1, 3, 16, 32)\n",
    "with torch.no_grad():\n",
    "    enchant_n_output = enchant_n_model(enchant_n_sample)\n",
    "torch.onnx.export(\n",
    "    enchant_n_model,\n",
    "    enchant_n_sample,\n",
    "    'onnx_models/enchant_n_resnet18_aug_1.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "ort_session = ort.InferenceSession('onnx_models/enchant_n_resnet18_aug_1.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: enchant_n_sample.detach().numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "np.testing.assert_allclose(enchant_n_output.detach().numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(enchant_n_output.detach().numpy()[0][:10])\n",
    "print(ort_outs[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-11.827245   -10.277574    -9.819902   -14.344846    -0.02018761\n",
      "   0.2792394    1.075137    -8.602564    -2.5980327    0.2627149 ]\n",
      "[-11.827242   -10.27757     -9.819905   -14.344847    -0.02018636\n",
      "   0.27923828   1.0751365   -8.602562    -2.5980315    0.26271605]\n"
     ]
    }
   ],
   "source": [
    "option_sample = torch.randn(1, 3, 20, 105)\n",
    "with torch.no_grad():\n",
    "    option_output = option_model(option_sample)\n",
    "torch.onnx.export(\n",
    "    option_model,\n",
    "    option_sample,\n",
    "    'onnx_models/option_resnet18_aug_1.onnx',\n",
    "    export_params=True,\n",
    "    opset_version=16,\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "ort_session = ort.InferenceSession('onnx_models/option_resnet18_aug_1.onnx')\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: option_sample.detach().numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "np.testing.assert_allclose(option_output.detach().numpy(), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(option_output.detach().numpy()[0][:10])\n",
    "print(ort_outs[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
